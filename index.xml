<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Yann Hamon</title><link>https://yann.mandragor.org/</link><description>Recent content on Yann Hamon</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 21 Jul 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://yann.mandragor.org/index.xml" rel="self" type="application/rss+xml"/><item><title>ðŸ˜´ The Internet sleeps at night ðŸŒ™</title><link>https://yann.mandragor.org/posts/the-internet-sleeps-at-night/</link><pubDate>Sun, 21 Jul 2024 00:00:00 +0000</pubDate><guid>https://yann.mandragor.org/posts/the-internet-sleeps-at-night/</guid><description>Does it ever feel like the internet is slower at night?
Did you, like me, assume that the time of day should have nothing to do with internet speed?
Today, we will look into the following graph, showing increased average and median latency during night-time for a large website as experienced by users in South America. By understanding Content Delivery Networks (CDNs), TCP, and stateful HTTP connections better, we will demonstrate why a large portion of websites is indeed slightly slower at night.</description></item><item><title>The curious case of the CDN Cache-HISS</title><link>https://yann.mandragor.org/posts/cache-hiss/</link><pubDate>Sun, 06 Aug 2023 00:00:00 +0000</pubDate><guid>https://yann.mandragor.org/posts/cache-hiss/</guid><description>A few years ago, I was asked to take a more active role maintaining the CDN configuration of the company I work for. My knowledge of CDNs at the time was pretty basic and could be summarised by the following diagram:
&amp;ldquo;Sure, I got this&amp;rdquo;. And for a short time, things were good. But soon after, I was asked the following question:
&amp;ldquo;We are reviewing the performance of a client&amp;rsquo;s requests - several of their requests are quite slow, despite being Cache HITs.</description></item><item><title>The execution model of AWS Lambda@edge with Cloudfront's two- and three-tiered architecture</title><link>https://yann.mandragor.org/posts/lambda-execution-model/</link><pubDate>Fri, 02 Jul 2021 00:00:00 +0000</pubDate><guid>https://yann.mandragor.org/posts/lambda-execution-model/</guid><description>The introduction of Lambda@Edge in 2016/2017 was probably the most significant update to AWS Cloudfront in the last decade. By enabling customers to run code directly in Cloudfront&amp;rsquo;s Points-Of-Presence (POPs), AWS was at the forefront of edge computing, leveraging countless use-cases, from simple header manipulation, to custom authentication workflows.
Lambda@Edge relies on a simple execution model that defines four different types of lambda functions that can manipulate CloudFront request or response objects:</description></item><item><title>Solving the CDN post-purge thundering herd problem: The PurgeGroup pattern</title><link>https://yann.mandragor.org/posts/purge-group-pattern/</link><pubDate>Sat, 12 Jun 2021 00:00:00 +0000</pubDate><guid>https://yann.mandragor.org/posts/purge-group-pattern/</guid><description>Purging a Content Delivery Network (CDN) cache can be a risky endeavour. Since a CDN usually heavily caches requests, the origin only receives a fraction of all customers' traffic.
For a short amount of time following a purge operation, the CDN cache is empty and all incoming requests are sent to the origin. If the cache hit ratio is usually around 98%, the number of requests hitting the origin immediately after the purge might be up to 50 times greater than usual.</description></item><item><title>Ensuring Kubernetes manifests validity &amp; compliance - a tooling overview</title><link>https://yann.mandragor.org/external_publications/manifests-validity-compliance/</link><pubDate>Fri, 18 Dec 2020 00:00:00 +0000</pubDate><guid>https://yann.mandragor.org/external_publications/manifests-validity-compliance/</guid><description>In an Infrastructure as code / GitOps world, testing that your Kubernetes configuration is correct, secure, and compliant to your company&amp;rsquo;s requirements &amp;amp; best practices is more important than ever. An increasingly large list of tools is there to help you - linters, validators, testing frameworks, admission controllers&amp;hellip; each working in subtly different ways. [&amp;hellip;]</description></item><item><title>Open-sourcing kube-secret-syncer: A Kubernetes operator to sync secrets from AWS Secrets Manager</title><link>https://yann.mandragor.org/external_publications/kube-secret-syncer/</link><pubDate>Tue, 20 Oct 2020 00:00:00 +0000</pubDate><guid>https://yann.mandragor.org/external_publications/kube-secret-syncer/</guid><description>Weâ€™re releasing the open source code for Kube-secret-syncer, a Kubernetes operator that syncs secrets from AWS Secrets Manager. This operator improves on existing projects by delivering sophisticated access control, templated fields and caching to reduce costs. For those familiar with the struggles that come from synching secrets between the two, we hope this comes as a welcome solution. [&amp;hellip;]</description></item><item><title>Creating greater reliability: CoreDNS-nodecache</title><link>https://yann.mandragor.org/external_publications/coredns-nodecache/</link><pubDate>Tue, 07 Jan 2020 00:00:00 +0000</pubDate><guid>https://yann.mandragor.org/external_publications/coredns-nodecache/</guid><description>Ongoing issues in the Linux kernelâ€™s UDP connection tracking have caused challenges with DNS, and bugs particularly affect DNS in Kubernetes in its default configuration; we saw elevated rates of DNS failures that seemed to increase with load on our clusters. Other developers have reported these problems in blog posts, such as Racy conntrack and DNS lookup timeouts and a reason for unexplained connection timeouts on Kubernetes/Docker. In these cases, a race condition in the kernel [&amp;hellip;]</description></item><item><title>Making S3 more resilient using Lambda@Edge</title><link>https://yann.mandragor.org/external_publications/making-s3-more-resilient/</link><pubDate>Wed, 27 Feb 2019 00:00:00 +0000</pubDate><guid>https://yann.mandragor.org/external_publications/making-s3-more-resilient/</guid><description>Using Lambda@Edge in CloudFront, Contentful created a solution to actively serve requests from multiple S3 backends (circumventing an AWS restriction) to ensure resiliency to regional outages. As the company progressed, it built tooling to adopt Lambda@Edge as a software platform into its stack, which, at the end, allowed it to build high-performant complex logic on it.</description></item></channel></rss>